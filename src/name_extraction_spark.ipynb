{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to find scraped charity names in the Panama Papers using Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import re\n",
    "import nltk\n",
    "import json\n",
    "import folium\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#stop words\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#spark\n",
    "import findspark\n",
    "findspark.init('/opt/spark/spark-2.3.2-bin-hadoop2.7/')\n",
    "\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import min\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.functions import explode\n",
    "\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import TimestampType\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "DATA_FOLDER = '../data'\n",
    "PANAMA_DATA_FOLDER = DATA_FOLDER + '/panama'\n",
    "\n",
    "GENERATED_FOLDER = '../generated'\n",
    "CHARITY_GENERATED_FOLDER = GENERATED_FOLDER + '/charities'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and creation of dataframes\n",
    "pp_edges = spark.read.csv(PANAMA_DATA_FOLDER + '/panama_papers.edges.csv', header=True)\n",
    "pp_adress = spark.read.csv(PANAMA_DATA_FOLDER + '/panama_papers.nodes.address.csv', header=True)\n",
    "pp_entity = spark.read.csv(PANAMA_DATA_FOLDER + '/panama_papers.nodes.entity.csv', header=True)\n",
    "pp_intermediary = spark.read.csv(PANAMA_DATA_FOLDER + '/panama_papers.nodes.intermediary.csv', header=True)\n",
    "pp_officer = spark.read.csv(PANAMA_DATA_FOLDER + '/panama_papers.nodes.officer.csv', header=True)\n",
    "\n",
    "wiki_info = spark.read.csv(CHARITY_GENERATED_FOLDER + '/wikipedia_charity_info.csv', header=True)\n",
    "wiki_links =charities_info = spark.read.csv(CHARITY_GENERATED_FOLDER + '/wikipedia_charity_links.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/sabrina/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Addition of english stop words\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "stop_words.add('&')\n",
    "stop_words.add('co')\n",
    "stop_words.add('co.')\n",
    "stop_words.add('co.,')\n",
    "stop_words.add('co.,ltd.')\n",
    "stop_words.add('corp')\n",
    "stop_words.add('corp.')\n",
    "stop_words.add('corp.,')\n",
    "stop_words.add('de')\n",
    "stop_words.add('foundation')\n",
    "stop_words.add('inc')\n",
    "stop_words.add('inc.')\n",
    "stop_words.add('limited')\n",
    "stop_words.add('international')\n",
    "stop_words.add('ltd')\n",
    "stop_words.add('ltd.')\n",
    "stop_words.add('s.a.')\n",
    "stop_words.add('world')\n",
    "stop_words.add('global')\n",
    "\n",
    "demi_stop_words = set()\n",
    "demi_stop_words.add('family')\n",
    "demi_stop_words = list(demi_stop_words)\n",
    "\n",
    "stop_words = list(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting each charity name and cleaning stop words\n",
    "\n",
    "def to_lower_parens_less(word):\n",
    "    return word.lower().replace('(', '').replace(')', '')\n",
    "\n",
    "charity_name = wiki_info.select('Name').selectExpr('Name as CharityName')\n",
    "def remove_stop(word_list):\n",
    "    return [to_lower_parens_less(w) for w in word_list if w.lower() not in stop_words]\n",
    "    \n",
    "# Extracting company shell names\n",
    "\n",
    "shell_name=pp_entity.select('name').selectExpr('name as ShellName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(CharityName='AARP Foundation'),\n",
       " Row(CharityName=\"Acorns Children's Hospice\"),\n",
       " Row(CharityName='Action Against Hunger'),\n",
       " Row(CharityName='Action Deafness'),\n",
       " Row(CharityName='ActionAid')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charity_name.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(ShellName='TIANSHENG INDUSTRY AND TRADING CO., LTD.'),\n",
       " Row(ShellName='NINGBO SUNRISE ENTERPRISES UNITED CO., LTD.'),\n",
       " Row(ShellName='HOTFOCUS CO., LTD.'),\n",
       " Row(ShellName='SKY-BLUE GIFTS & TOYS CO., LTD.'),\n",
       " Row(ShellName='FORTUNEMAKER INVESTMENTS CORPORATION')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shell_name.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "charities_vs_shells = shell_name.crossJoin(charity_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(ShellName='TIANSHENG INDUSTRY AND TRADING CO., LTD.', CharityName='AARP Foundation'),\n",
       " Row(ShellName='TIANSHENG INDUSTRY AND TRADING CO., LTD.', CharityName=\"Acorns Children's Hospice\"),\n",
       " Row(ShellName='TIANSHENG INDUSTRY AND TRADING CO., LTD.', CharityName='Action Against Hunger'),\n",
       " Row(ShellName='TIANSHENG INDUSTRY AND TRADING CO., LTD.', CharityName='Action Deafness'),\n",
       " Row(ShellName='TIANSHENG INDUSTRY AND TRADING CO., LTD.', CharityName='ActionAid')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charities_vs_shells.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_words(charity, shell):\n",
    "    percentage = 0.6\n",
    "    percentage_sparse = 0.8\n",
    "    \n",
    "    if charity is None or shell is None:\n",
    "        return False\n",
    "    \n",
    "    charity_words = [x.lower() for x in charity.split()]\n",
    "    shell_words = [x.lower() for x in shell.split()]\n",
    "    len_charity = len(charity_words)\n",
    "    len_shell = len(shell_words)\n",
    "    \n",
    "    count_exact_matches = 0\n",
    "    count_random_matches = 0\n",
    "    stop_word_exact_matches = 0\n",
    "    stop_word_random_matches = 0\n",
    "    \n",
    "    for i in range(len_charity):\n",
    "        word = charity_words[i]\n",
    "        if word in shell_words:\n",
    "            count_random_matches += 1\n",
    "            \n",
    "            if i < len_shell and word == shell_words[i]:\n",
    "                count_exact_matches += 1\n",
    "                \n",
    "                if word in stop_words:\n",
    "                    stop_word_exact_matches += 1\n",
    "            \n",
    "            if word in stop_words:\n",
    "                stop_word_random_matches += 1\n",
    "                \n",
    "                \n",
    "    #if only stopwords match, not valid\n",
    "    if count_random_matches - stop_word_random_matches < 1:\n",
    "        return False\n",
    "    \n",
    "    #\"Family foundations are tricky -> make sure they are not the only matching parts\"\n",
    "    if ('family' in shell_words \n",
    "        and 'foundation' in shell_words \n",
    "        and 'family' in charity_words \n",
    "        and 'foundation' in charity_words \n",
    "        and count_random_matches < 3 \n",
    "        and len_shell > 2 \n",
    "        and len_charity > 2):\n",
    "        return False\n",
    "\n",
    "    if len_charity == 1 or len_shell == 1:\n",
    "        return (np.abs(len_charity - len_shell) < 2  and count_random_matches == 1)\n",
    "        \n",
    "    return ((count_random_matches/len_charity >= percentage) \n",
    "            and (count_random_matches/len_shell >= percentage))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = charities_vs_shells.rdd.filter(lambda r: check_for_words(r[0], r[1]) == True)\n",
    "filtered.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = filtered.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.write.format(\"csv\").mode('overwrite').save('../generated/panama_charity_matches.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
