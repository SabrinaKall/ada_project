{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check whether a match's charity headquarters (if available) match a shell company's address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "\n",
    "#spark\n",
    "import findspark\n",
    "findspark.init('/opt/spark/spark-2.3.2-bin-hadoop2.7/')\n",
    "\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import min\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.functions import explode\n",
    "\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import TimestampType\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from operator import itemgetter\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from community import community_louvain\n",
    "from networkx.algorithms.community.centrality import girvan_newman\n",
    "import itertools\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_file(leak, charity):\n",
    "    return '../generated/matches/' + leak + '_' + charity + '_matches.csv'\n",
    "\n",
    "#Load matches\n",
    "panama_wiki_matches = spark.read.csv(get_match_file('panama', 'wikipedia'), header=True)\n",
    "panama_ingo_matches = spark.read.csv(get_match_file('panama', 'INGO'), header=True)\n",
    "panama_forbes_matches = spark.read.csv(get_match_file('panama', 'forbes'), header=True)\n",
    "\n",
    "matches = panama_wiki_matches.union(panama_forbes_matches).union(panama_ingo_matches).drop('_c0')\n",
    "\n",
    "#Load edges\n",
    "edges = spark.read.csv('../data/panama/panama_papers.edges.csv', header=True)\n",
    "\n",
    "address_nodes = spark.read.csv('../data/panama/panama_papers.nodes.address.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
